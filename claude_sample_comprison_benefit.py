import os
import streamlit as st
import pandas as pd
from dotenv import load_dotenv
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain.chains import RetrievalQA
from langchain_anthropic import ChatAnthropicMessages

# âœ… í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
if not os.getenv("ANTHROPIC_API_KEY"):
    st.error("âŒ .env íŒŒì¼ì— ANTHROPIC_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
    st.stop()

# âœ… PDF ê²½ë¡œ
ROOT_DIR = "C:/_knudata/hyundaicar_info"
BENEFIT_PDF_PATH = os.path.join(ROOT_DIR, "í˜„ëŒ€ì°¨_ì´ë‹¬ì˜_í˜œíƒ.pdf")

# âœ… Streamlit ì„¤ì •
st.set_page_config(page_title="ğŸš— í˜„ëŒ€ì°¨ Claude RAG ë°ëª¨", layout="wide")
st.title("ğŸš— í˜„ëŒ€ì°¨ Claude ê¸°ë°˜ RAG ë°ëª¨")
st.caption("ì¹´íƒˆë¡œê·¸ + ê°€ê²©í‘œ ê¸°ë°˜ RAG ì‘ë‹µê³¼ Claude ê¸°ë³¸ ì‘ë‹µ ë¹„êµ")

# âœ… ì´ë‹¬ì˜ í˜œíƒ í‘œ ë°ì´í„° (PDF ë‚´ìš© í•˜ë“œì½”ë”©)
benefit_data = [
    ("ê·¸ëœì €", "3,798ë§Œì›", "170ë§Œì›"),
    ("ê·¸ëœì € Hybrid", "4,354ë§Œì›", "170ë§Œì›"),
    ("ì•„ë°˜ë–¼", "2,034ë§Œì›", "155ë§Œì›"),
    ("ì•„ë°˜ë–¼ Hybrid", "2,523ë§Œì›", "155ë§Œì›"),
    ("ì˜ë‚˜íƒ€ ë”” ì—£ì§€", "2,788ë§Œì›", "250ë§Œì›"),
    ("ì˜ë‚˜íƒ€ ë”” ì—£ì§€ Hybrid", "3,232ë§Œì›", "250ë§Œì›"),
    ("ì½”ë‚˜", "2,446ë§Œì›", "155ë§Œì›"),
    ("ì½”ë‚˜ Hybrid", "2,955ë§Œì›", "155ë§Œì›"),
    ("ë² ë‰´", "1,956ë§Œì›", "155ë§Œì›"),
    ("ë”” ì˜¬ ë‰´ íŒ°ë¦¬ì„¸ì´ë“œ", "4,383ë§Œì›", "126ë§Œì›"),
    ("ë”” ì˜¬ ë‰´ íŒ°ë¦¬ì„¸ì´ë“œ Hybrid", "4,968ë§Œì›", "126ë§Œì›"),
    ("íˆ¬ì‹¼", "2,729ë§Œì›", "250ë§Œì›"),
    ("íˆ¬ì‹¼ Hybrid", "3,205ë§Œì›", "250ë§Œì›"),
    ("ì‹¼íƒ€í˜", "3,492ë§Œì›", "250ë§Œì›"),
    ("ì‹¼íƒ€í˜ Hybrid", "3,870ë§Œì›", "150ë§Œì›"),
    ("ìŠ¤íƒ€ë¦¬ì•„ ë¼ìš´ì§€", "3,780ë§Œì›", "335ë§Œì›"),
    ("ìŠ¤íƒ€ë¦¬ì•„ ë¼ìš´ì§€ Hybrid", "4,110ë§Œì›", "235ë§Œì›"),
    ("ìŠ¤íƒ€ë¦¬ì•„", "2,847ë§Œì›", "335ë§Œì›"),
    ("ìŠ¤íƒ€ë¦¬ì•„ Hybrid", "3,433ë§Œì›", "235ë§Œì›"),
    ("ìŠ¤íƒ€ë¦¬ì•„ í‚¨ë”", "3,643ë§Œì›", "335ë§Œì›"),
    ("ìŠ¤íƒ€ë¦¬ì•„ ë¼ìš´ì§€ ìº í¼", "7,094ë§Œì›", "335ë§Œì›"),
    ("ìŠ¤íƒ€ë¦¬ì•„ ë¼ìš´ì§€ ìº í¼ Hybrid", "7,436ë§Œì›", "235ë§Œì›"),
    ("ìŠ¤íƒ€ë¦¬ì•„ ë¼ìš´ì§€ ë¦¬ë¬´ì§„", "5,911ë§Œì›", "335ë§Œì›"),
    ("ìŠ¤íƒ€ë¦¬ì•„ ë¼ìš´ì§€ ë¦¬ë¬´ì§„ Hybrid", "6,241ë§Œì›", "235ë§Œì›"),
    ("ë” ë‰´ ì•„ì´ì˜¤ë‹‰ 6", "4,856ë§Œì›", "780ë§Œì›"),
    ("ë”” ì˜¬ ë‰´ ë„¥ì˜", "7,643ë§Œì›", "495ë§Œì›"),
    ("ì•„ì´ì˜¤ë‹‰ 5", "4,740ë§Œì›", "600ë§Œì›"),
    ("ì½”ë‚˜ Electric", "4,152ë§Œì›", "685ë§Œì›"),
    ("ì•„ì´ì˜¤ë‹‰ 9", "6,715ë§Œì›", "370ë§Œì›"),
    ("ST1", "5,655ë§Œì›", "475ë§Œì›"),
    ("í¬í„° II Electric", "4,325ë§Œì›", "485ë§Œì›"),
    ("ì•„ë°˜ë–¼ N", "3,360ë§Œì›", "455ë§Œì›"),
    ("ì•„ì´ì˜¤ë‹‰ 5 N", "7,700ë§Œì›", "780ë§Œì›"),
    ("í¬í„° II", "2,028ë§Œì›", "185ë§Œì›"),
]
benefit_df = pd.DataFrame(benefit_data, columns=["ì°¨ëŸ‰ëª…", "ì‹œì‘ê°€(~ë¶€í„°)", "ìµœëŒ€í• ì¸"])

model_name_map = {
    "grandeur": "ê·¸ëœì €",
    "grandeur-hybrid": "ê·¸ëœì € Hybrid",
    "avante": "ì•„ë°˜ë–¼",
    "avante-hybrid": "ì•„ë°˜ë–¼ Hybrid",
    "sonata-the-edge": "ì˜ë‚˜íƒ€ ë”” ì—£ì§€",
    "sonata-the-edge-hybrid": "ì˜ë‚˜íƒ€ ë”” ì—£ì§€ Hybrid",
    "kona": "ì½”ë‚˜",
    "kona-hybrid": "ì½”ë‚˜ Hybrid",
    "venue": "ë² ë‰´",
    "the-all-new-palisade": "ë”” ì˜¬ ë‰´ íŒ°ë¦¬ì„¸ì´ë“œ",
    "the-all-new-palisade-hybrid": "ë”” ì˜¬ ë‰´ íŒ°ë¦¬ì„¸ì´ë“œ Hybrid",
    "tucson": "íˆ¬ì‹¼",
    "tucson-hybrid": "íˆ¬ì‹¼ Hybrid",
    "santafe": "ì‹¼íƒ€í˜",
    "santafe-hybrid": "ì‹¼íƒ€í˜ Hybrid",
    "staria-lounge": "ìŠ¤íƒ€ë¦¬ì•„ ë¼ìš´ì§€",
    "staria-lounge-hybrid": "ìŠ¤íƒ€ë¦¬ì•„ ë¼ìš´ì§€ Hybrid",
    "staria": "ìŠ¤íƒ€ë¦¬ì•„",
    "staria-hybrid": "ìŠ¤íƒ€ë¦¬ì•„ Hybrid",
    "staria-kinder": "ìŠ¤íƒ€ë¦¬ì•„ í‚¨ë”",
    "staria-lounge-camper": "ìŠ¤íƒ€ë¦¬ì•„ ë¼ìš´ì§€ ìº í¼",
    "staria-lounge-camper-hybrid": "ìŠ¤íƒ€ë¦¬ì•„ ë¼ìš´ì§€ ìº í¼ Hybrid",
    "staria-lounge-limousine": "ìŠ¤íƒ€ë¦¬ì•„ ë¼ìš´ì§€ ë¦¬ë¬´ì§„",
    "staria-lounge-limousine-hybrid": "ìŠ¤íƒ€ë¦¬ì•„ ë¼ìš´ì§€ ë¦¬ë¬´ì§„ Hybrid",
    "the-new-ioniq6": "ë” ë‰´ ì•„ì´ì˜¤ë‹‰ 6",
    "the-all-new-nexo": "ë”” ì˜¬ ë‰´ ë„¥ì˜",
    "ioniq5": "ì•„ì´ì˜¤ë‹‰ 5",
    "kona-electric": "ì½”ë‚˜ Electric",
    "ioniq9": "ì•„ì´ì˜¤ë‹‰ 9",
    "st1": "ST1",
    "porter2-electric": "í¬í„° II Electric",
    "avante-n": "ì•„ë°˜ë–¼ N",
    "ioniq5-n": "ì•„ì´ì˜¤ë‹‰ 5 N",
    "porter2": "í¬í„° II",
}

# âœ… ì´ë‹¬ì˜ í˜œíƒ ë³´ê¸°
with st.expander("ğŸ“„ ì´ë‹¬ì˜ êµ¬ë§¤ í˜œíƒ ë³´ê¸°", expanded=False):
    st.dataframe(benefit_df, use_container_width=True)

def get_benefit_for_model(model_name_en: str, benefit_df: pd.DataFrame, name_map: dict) -> str:
    kor_name = name_map.get(model_name_en)
    if not kor_name:
        return "âŒ í•´ë‹¹ ì°¨ëŸ‰ì˜ í•œê¸€ ëª¨ë¸ëª…ì´ ë§¤í•‘ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    
    matched = benefit_df[benefit_df["ì°¨ëŸ‰ëª…"] == kor_name]
    if matched.empty:
        return f"ğŸ” `{kor_name}` ì°¨ëŸ‰ì— ëŒ€í•œ í˜œíƒ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    row = matched.iloc[0]
    return f"ğŸ’¸ **{kor_name}**\n\nğŸ‘‰ ì‹œì‘ê°€: `{row['ì‹œì‘ê°€(~ë¶€í„°)']}`\nğŸ‘‰ ìµœëŒ€ í• ì¸: `{row['ìµœëŒ€í• ì¸']}`"


# âœ… ì „ì²´ ì°¨ëŸ‰ íƒìƒ‰
def get_all_car_models():
    models = []
    for category in os.listdir(ROOT_DIR):
        category_path = os.path.join(ROOT_DIR, category)
        if os.path.isdir(category_path):
            for model in os.listdir(category_path):
                model_path = os.path.join(category_path, model)
                if os.path.isdir(model_path):
                    models.append((os.path.join(category, model), model))
    return models

car_model_map = get_all_car_models()
car_model_options = [model_name for _, model_name in car_model_map]
selected_models = st.multiselect("ğŸš˜ ì°¨ì¢… ì„ íƒ (1ê°œ ë˜ëŠ” 2ê°œ)", car_model_options)

# âœ… Vectorstore ë¡œë”©
@st.cache_resource
def load_vectorstore_combined(pdf_paths):
    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    all_docs = []
    for path in pdf_paths:
        docs = PyPDFLoader(path).load()
        chunks = splitter.split_documents(docs)
        all_docs.extend(chunks)

    embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
    vectordb = Chroma.from_documents(all_docs, embedding=embeddings)
    return vectordb

# âœ… Claude ì‘ë‹µ
def answer_with_claude(vectorstore, query):
    retriever = vectorstore.as_retriever()
    llm = ChatAnthropicMessages(
        model="claude-3-5-sonnet-20240620",
        temperature=0,
        api_key=os.getenv("ANTHROPIC_API_KEY")
    )
    qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)
    return qa_chain.run(query)

# âœ… ì°¨ëŸ‰ 1ê°œ ì„ íƒ: Claude ê¸°ë³¸ + Hyundai RAG ë¹„êµ
if len(selected_models) == 1:
    model_rel_path, model_name = next((fp, dn) for fp, dn in car_model_map if dn == selected_models[0])

    # âœ… ì´ë‹¬ì˜ í˜œíƒ í‘œì‹œ
    with st.expander("ğŸ’¸ ì„ íƒ ì°¨ëŸ‰ ì´ë‹¬ì˜ í˜œíƒ", expanded=True):
        benefit_text = get_benefit_for_model(model_name, benefit_df, model_name_map)
        st.markdown(benefit_text)

    base_path = os.path.join(ROOT_DIR, model_rel_path)
    catalog_path = os.path.join(base_path, f"{model_name}-catalog.pdf")
    price_path = os.path.join(base_path, f"{model_name}-price.pdf")

    if not os.path.exists(catalog_path) or not os.path.exists(price_path):
        st.error("âŒ ì¹´íƒˆë¡œê·¸ ë˜ëŠ” ê°€ê²©í‘œ PDFê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        vectordb = load_vectorstore_combined([catalog_path, price_path])

        st.subheader(f"ğŸš˜ [{model_name}] ì°¨ëŸ‰ ì§ˆë¬¸")
        question = st.text_input("â“ ê¶ê¸ˆí•œ ì ì„ ì…ë ¥í•˜ì„¸ìš”")

        if question:
            with st.spinner("Claude ì‘ë‹µ ìƒì„± ì¤‘..."):
                llm = ChatAnthropicMessages(
                    model="claude-3-5-sonnet-20240620",
                    temperature=0,
                    api_key=os.getenv("ANTHROPIC_API_KEY")
                )

                # 1ï¸âƒ£ Claude ê¸°ë³¸ ì‘ë‹µ
                base_response = llm.invoke(question).content

                # 2ï¸âƒ£ Hyundai RAG
                rag_qa = RetrievalQA.from_chain_type(llm=llm, retriever=vectordb.as_retriever())
                rag_response = rag_qa.invoke({"query": question})["result"]

            st.markdown("---")
            st.markdown(f"### ğŸš˜ ì°¨ëŸ‰: `{model_name}` | â“ ì§ˆë¬¸: `{question}`")

            col1, col2 = st.columns(2)
            with col1:
                st.markdown("ğŸ§  **Claude ê¸°ë³¸ ì‘ë‹µ**")
                st.write(base_response)
            with col2:
                st.markdown("ğŸ” **í˜„ëŒ€ì°¨ PDF ê¸°ë°˜ RAG ì‘ë‹µ**")
                st.write(rag_response)

# âœ… ì°¨ëŸ‰ 2ê°œ ì„ íƒ: Hyundai RAG ì‘ë‹µ ë¹„êµ
elif len(selected_models) == 2:
    st.subheader(f"ğŸ“Š ì°¨ëŸ‰ ë¹„êµ: {selected_models[0]} vs {selected_models[1]}")
    question = st.text_input("ë¹„êµí•  ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”")

    def load_both_vectorstores():
        vectordbs = []
        for name in selected_models:
            rel_path, model_name = next((fp, dn) for fp, dn in car_model_map if dn == name)
            base_path = os.path.join(ROOT_DIR, rel_path)
            catalog_path = os.path.join(base_path, f"{model_name}-catalog.pdf")
            price_path = os.path.join(base_path, f"{model_name}-price.pdf")
            if os.path.exists(catalog_path) and os.path.exists(price_path):
                vectordb = load_vectorstore_combined([catalog_path, price_path])
                vectordbs.append((model_name, vectordb))
        return vectordbs

    if question:
        db_pairs = load_both_vectorstores()
        if len(db_pairs) != 2:
            st.error("â— ë‘ ì°¨ëŸ‰ì˜ ì¹´íƒˆë¡œê·¸/ê°€ê²©í‘œ PDFê°€ ëª¨ë‘ ì¡´ì¬í•´ì•¼ í•©ë‹ˆë‹¤.")
        else:
            with st.spinner("Claude RAG ë¹„êµ ì‘ë‹µ ìƒì„± ì¤‘..."):
                rag1 = answer_with_claude(db_pairs[0][1], question)
                rag2 = answer_with_claude(db_pairs[1][1], question)

            col1, col2 = st.columns(2)
            with col1:
                st.markdown(f"### ğŸ“˜ {db_pairs[0][0]} (í˜„ëŒ€ì°¨ RAG ì‘ë‹µ)")
                st.write(rag1)
            with col2:
                st.markdown(f"### ğŸ“˜ {db_pairs[1][0]} (í˜„ëŒ€ì°¨ RAG ì‘ë‹µ)")
                st.write(rag2)
