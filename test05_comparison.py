# ì•ˆì „í•œ ì˜ˆì‹œ (.envì—ì„œ ë¶ˆëŸ¬ì˜¤ê¸°)
import os
from dotenv import load_dotenv
load_dotenv()

import openai
openai.api_key = os.getenv("OPENAI_API_KEY")


import streamlit as st
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import Chroma
from langchain.chains import RetrievalQA

# ğŸ“„ PDF ê²½ë¡œ
catalog_path = "grandeur-catalog.pdf"
price_path = "grandeur-2026-price.pdf"

# ğŸ“˜ Streamlit ì„¤ì •
st.set_page_config(page_title="RAG ë¹„êµ ë°ëª¨", layout="wide")
st.title("ğŸ“Š GPT-4o ë‹¨ë… vs RAG PDF ê¸°ë°˜ ì‘ë‹µ ë¹„êµ")
st.caption("ì¹´íƒˆë¡œê·¸/ê°€ê²©í‘œ PDFë¥¼ í™œìš©í•œ ì§ˆì˜ì‘ë‹µ ì„±ëŠ¥ ë¹„êµ")

# ğŸ“¦ ë²¡í„°ìŠ¤í† ì–´ ë¡œë”©
@st.cache_resource
def load_vectorstores():
    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    embedding = OpenAIEmbeddings()

    catalog_chunks = splitter.split_documents(PyPDFLoader(catalog_path).load())
    price_chunks = splitter.split_documents(PyPDFLoader(price_path).load())

    catalog_db = Chroma.from_documents(catalog_chunks, embedding=embedding, collection_name="grandeur_catalog")
    price_db = Chroma.from_documents(price_chunks, embedding=embedding, collection_name="grandeur_price")

    return catalog_db, price_db

catalog_db, price_db = load_vectorstores()

# âœ… ì‚¬ìš©ì ì§ˆë¬¸ ì…ë ¥
question = st.text_input("â“ ë¹„êµí•  ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”", placeholder="ì˜ˆ: í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ì˜ ì¶œë ¥ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?")

# âœ… ì‘ë‹µ ìƒì„± ë° ì¶œë ¥
if question:
    with st.spinner("ğŸ¤– GPT-4oê°€ ì‘ë‹µì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
        llm = ChatOpenAI(model_name="gpt-4o")
        
        # 1ï¸âƒ£ GPT ê¸°ë³¸ ì‘ë‹µ
        gpt_response = llm.invoke(question).content

        # 2ï¸âƒ£ ì¹´íƒˆë¡œê·¸ RAG ì‘ë‹µ
        catalog_qa = RetrievalQA.from_chain_type(llm=llm, retriever=catalog_db.as_retriever())
        catalog_response = catalog_qa.invoke({"query": question})["result"]

        # 3ï¸âƒ£ ê°€ê²©í‘œ RAG ì‘ë‹µ
        price_qa = RetrievalQA.from_chain_type(llm=llm, retriever=price_db.as_retriever())
        price_response = price_qa.invoke({"query": question})["result"]

    st.markdown("---")
    st.markdown(f"### â“ ì§ˆë¬¸: {question}")

    col1, col2, col3 = st.columns(3)
    with col1:
        st.markdown("ğŸ§  **GPT ê¸°ë³¸ ì‘ë‹µ**")
        st.write(gpt_response)

    with col2:
        st.markdown("ğŸ“˜ **ì¹´íƒˆë¡œê·¸ PDF ê¸°ë°˜ ì‘ë‹µ**")
        st.write(catalog_response)

    with col3:
        st.markdown("ğŸ’° **ê°€ê²©í‘œ PDF ê¸°ë°˜ ì‘ë‹µ**")
        st.write(price_response)
