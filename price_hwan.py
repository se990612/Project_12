# ğŸ“„ pages/3_ê°€ê²©í‘œ_QnA.py
import os
import streamlit as st
from dotenv import load_dotenv
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain.chains import RetrievalQA
from langchain_anthropic import ChatAnthropicMessages
from langchain.prompts import PromptTemplate
import pandas as pd

#fd

# âœ… í™˜ê²½ì„¤ì •
load_dotenv()
st.set_page_config(page_title="ğŸ’µ ê°€ê²©í‘œ Q&A", layout="wide")
st.title("ğŸ’µ ì°¨ëŸ‰ ê°€ê²©í‘œ ê¸°ë°˜ Claude RAG ì§ˆì˜ì‘ë‹µ")

ROOT_DIR = "C:/Users/KDT13/kh0616/project_12/Project_12/hyundaicar_info"
VECTORSTORE_DIR = "C:/Users/KDT13/kh0616/project_12/Project_12/vector_db/price"

# âœ… ì°¨ëŸ‰ íƒìƒ‰ í•¨ìˆ˜
def get_all_car_models():
    models = []
    for category in os.listdir(ROOT_DIR):
        category_path = os.path.join(ROOT_DIR, category)
        if os.path.isdir(category_path):
            for model in os.listdir(category_path):
                model_path = os.path.join(category_path, model)
                if os.path.isdir(model_path):
                    models.append((os.path.join(category, model), model))
    return models

car_model_map = get_all_car_models()
car_model_options = [model_name for _, model_name in car_model_map]
st.markdown("### ğŸ¯ ì˜µì…˜ 1: íŠ¹ì • ì°¨ì¢…ì— ëŒ€í•´ ê°€ê²© ì§ˆë¬¸í•˜ê¸°")
selected_model = st.selectbox("ğŸš— ì°¨ëŸ‰ ì„ íƒ", ["ì„ íƒ ì•ˆí•¨"] + car_model_options)

# âœ… FAISS ì €ì¥/ë¶ˆëŸ¬ì˜¤ê¸°
@st.cache_resource
def load_or_create_faiss(pdf_path, save_path):
    embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

    index_file = os.path.join(save_path, "index.faiss")
    pkl_file = os.path.join(save_path, "index.pkl")

    if os.path.exists(index_file) and os.path.exists(pkl_file):
        return FAISS.load_local(save_path, embeddings, allow_dangerous_deserialization=True)
    else:
        docs = PyPDFLoader(pdf_path).load()
        splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=200)
        chunks = splitter.split_documents(docs)
        vectordb = FAISS.from_documents(chunks, embeddings)

        os.makedirs(save_path, exist_ok=True)
        vectordb.save_local(save_path)
        return vectordb

# âœ… Claude ì‘ë‹µ í•¨ìˆ˜
def answer_with_claude(vectordb, query):
    retriever = vectordb.as_retriever(search_kwargs={"k": 5})

    llm = ChatAnthropicMessages(model="claude-3-5-sonnet-20240620", temperature=0)

    # âœ… ì¼ë°˜ LLMChainìš© í”„ë¡¬í”„íŠ¸ë¡œ ë³€ê²½
    prompt_template = PromptTemplate(
        input_variables=["context", "question"],
        template="""
    ë„ˆëŠ” ì°¨ëŸ‰ ì¹´íƒˆë¡œê·¸ PDFë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” ì „ë¬¸ê°€ì•¼.
    ì—°ë¹„, ë””ìì¸, ì˜µì…˜, ê°€ê²© ë“±ì„ ëª…í™•í•˜ê²Œ ì„¤ëª…í•˜ê³ , ë°˜ë“œì‹œ ë¬¸ì„œ ê¸°ë°˜ ì‚¬ì‹¤ë§Œ ì–¸ê¸‰í•´.

    ì§ˆë¬¸: {question}
    ë¬¸ì„œ ì •ë³´:
    {context}
    ë‹µë³€:
    """
    )

    qa = RetrievalQA.from_chain_type(
        llm=llm,
        retriever=retriever,
        chain_type="stuff",
        chain_type_kwargs={"prompt": prompt_template}
    )

    return qa.run(query)

# âœ… ì°¨ì¢… ê¸°ë°˜ ì§ˆë¬¸
if selected_model != "ì„ íƒ ì•ˆí•¨":
    rel_path, model_name = next((fp, dn) for fp, dn in car_model_map if dn == selected_model)
    price_path = os.path.join(ROOT_DIR, rel_path, f"{model_name}-price.pdf")

    if not os.path.exists(price_path):
        st.error("âŒ ê°€ê²©í‘œ PDFê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    else:
        st.success(f"ğŸ“„ {model_name} ê°€ê²©í‘œ ë¡œë“œ ì™„ë£Œ")
        question = st.text_input("ğŸ’¬ í•´ë‹¹ ì°¨ëŸ‰ì— ëŒ€í•´ ê¶ê¸ˆí•œ ê°€ê²© ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”")

        if question:
            with st.spinner("Claude RAG ì‘ë‹µ ìƒì„± ì¤‘..."):
                faiss_dir = os.path.join(VECTORSTORE_DIR, model_name)
                vectordb = load_or_create_faiss(price_path, faiss_dir)
                response = answer_with_claude(vectordb, question)

            st.markdown("---")
            st.markdown(f"### ğŸš— ì°¨ëŸ‰: `{model_name}`")
            st.markdown(f"### â“ ì§ˆë¬¸: `{question}`")
            st.markdown("---")
            st.markdown("### ğŸ¤– Claude RAG ì‘ë‹µ")
            st.write(response)

# âœ… ì˜ˆì‚° ê¸°ë°˜ í•„í„°ë§ ê¸°ëŠ¥
st.markdown("### ğŸ’¸ ì˜µì…˜ 2: ë‚´ ì˜ˆì‚°ì— ë§ëŠ” ì°¨ëŸ‰ ì¶”ì²œ")
budget_range = st.slider("ì˜ˆì‚° ë²”ìœ„ë¥¼ ì„ íƒí•˜ì„¸ìš”", 1000, 10000, (2500, 5000), step=100)

benefit_data = [
    ("ê·¸ëœì €", 3798, 170), ("ê·¸ëœì € Hybrid", 4354, 170), ("ì•„ë°˜ë–¼", 2034, 155), ("ì•„ë°˜ë–¼ Hybrid", 2523, 155),
    ("ì˜ë‚˜íƒ€ ë”” ì—£ì§€", 2788, 250), ("ì˜ë‚˜íƒ€ ë”” ì—£ì§€ Hybrid", 3232, 250), ("ì½”ë‚˜", 2446, 155), ("ì½”ë‚˜ Hybrid", 2955, 155),
    ("ë² ë‰´", 1956, 155), ("ë”” ì˜¬ ë‰´ íŒ°ë¦¬ì„¸ì´ë“œ", 4383, 126), ("ë”” ì˜¬ ë‰´ íŒ°ë¦¬ì„¸ì´ë“œ Hybrid", 4968, 126),
    ("íˆ¬ì‹¼", 2729, 250), ("íˆ¬ì‹¼ Hybrid", 3205, 250), ("ì‹¼íƒ€í˜", 3492, 250), ("ì‹¼íƒ€í˜ Hybrid", 3870, 150),
    ("ìŠ¤íƒ€ë¦¬ì•„ ë¼ìš´ì§€", 3780, 335), ("ìŠ¤íƒ€ë¦¬ì•„ ë¼ìš´ì§€ Hybrid", 4110, 235), ("ìŠ¤íƒ€ë¦¬ì•„", 2847, 335),
    ("ìŠ¤íƒ€ë¦¬ì•„ Hybrid", 3433, 235), ("ìŠ¤íƒ€ë¦¬ì•„ í‚¨ë”", 3643, 335), ("ìŠ¤íƒ€ë¦¬ì•„ ë¼ìš´ì§€ ìº í¼", 7094, 335),
    ("ìŠ¤íƒ€ë¦¬ì•„ ë¼ìš´ì§€ ìº í¼ Hybrid", 7436, 235), ("ìŠ¤íƒ€ë¦¬ì•„ ë¼ìš´ì§€ ë¦¬ë¬´ì§„", 5911, 335),
    ("ìŠ¤íƒ€ë¦¬ì•„ ë¼ìš´ì§€ ë¦¬ë¬´ì§„ Hybrid", 6241, 235), ("ë” ë‰´ ì•„ì´ì˜¤ë‹‰ 6", 4856, 780), ("ë”” ì˜¬ ë‰´ ë„¥ì˜", 7643, 495),
    ("ì•„ì´ì˜¤ë‹‰ 5", 4740, 600), ("ì½”ë‚˜ Electric", 4152, 685), ("ì•„ì´ì˜¤ë‹‰ 9", 6715, 370), ("ST1", 5655, 475),
    ("í¬í„° II Electric", 4325, 485), ("ì•„ë°˜ë–¼ N", 3360, 455), ("ì•„ì´ì˜¤ë‹‰ 5 N", 7700, 780), ("í¬í„° II", 2028, 185)
]

if st.button("ğŸš€ ì˜ˆì‚° ì ìš© ë° ì¶”ì²œ ì°¨ëŸ‰ ë³´ê¸°"):
    filtered = []
    for name, start_price, max_discount in benefit_data:
        discount_price = start_price - max_discount
        if budget_range[0] <= start_price <= budget_range[1] or budget_range[0] <= discount_price <= budget_range[1]:
            filtered.append((name, start_price, max_discount, discount_price))
    st.session_state["filtered_cars"] = pd.DataFrame(
        filtered, columns=["ì°¨ëŸ‰ëª…", "ì‹œì‘ê°€", "ìµœëŒ€ í• ì¸", "í˜œíƒ ì ìš©ê°€"]
    )

if "filtered_cars" in st.session_state and not st.session_state["filtered_cars"].empty:
    df_filtered = st.session_state["filtered_cars"]

    sort_column = st.selectbox("ì •ë ¬ ê¸°ì¤€", ["ì‹œì‘ê°€", "ìµœëŒ€ í• ì¸", "í˜œíƒ ì ìš©ê°€"])
    sort_order = st.radio("ì •ë ¬ ìˆœì„œ", ["ì˜¤ë¦„ì°¨ìˆœ", "ë‚´ë¦¼ì°¨ìˆœ"], horizontal=True)
    ascending = sort_order == "ì˜¤ë¦„ì°¨ìˆœ"

    df_filtered = df_filtered.sort_values(by=sort_column, ascending=ascending).reset_index(drop=True)

    st.success(f"ì˜ˆì‚° {budget_range[0]}ë§Œì› ~ {budget_range[1]}ë§Œì›ì— í•´ë‹¹í•˜ëŠ” ì°¨ëŸ‰:")
    st.dataframe(df_filtered, use_container_width=True)

    csv = df_filtered.to_csv(index=False).encode('utf-8-sig')
    st.download_button(
        label="ğŸ“¥ CSVë¡œ ì €ì¥í•˜ê¸°",
        data=csv,
        file_name="ì˜ˆì‚°ë³„_ì¶”ì²œ_ì°¨ëŸ‰.csv",
        mime="text/csv"
    )
