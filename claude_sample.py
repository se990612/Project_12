import os
import streamlit as st
from dotenv import load_dotenv
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain.chains import RetrievalQA
from langchain_anthropic import ChatAnthropicMessages

# âœ… í™˜ê²½ë³€ìˆ˜ ë¡œë“œ (.envì—ì„œ CLAUDE API KEY ì½ê¸°)
load_dotenv()
if not os.getenv("ANTHROPIC_API_KEY"):
    st.error("âŒ .env íŒŒì¼ì— ANTHROPIC_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
    st.stop()

# ğŸ“ í˜„ëŒ€ì°¨ ì •ë³´ í´ë” (ì ˆëŒ€ê²½ë¡œ)
ROOT_DIR = "C:/_knudata/hyundaicar_info"

if not os.path.exists(ROOT_DIR):
    st.error(f"âŒ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {ROOT_DIR}")
    st.stop()

# ğŸ” ì „ì²´ ì°¨ì¢… íƒìƒ‰
def get_all_car_models():
    models = []
    for category in os.listdir(ROOT_DIR):
        category_path = os.path.join(ROOT_DIR, category)
        if os.path.isdir(category_path):
            for model in os.listdir(category_path):
                model_path = os.path.join(category_path, model)
                if os.path.isdir(model_path):
                    models.append((os.path.join(category, model), model))
    return models

# ğŸš˜ ì°¨ì¢… ì„ íƒ
car_model_map = get_all_car_models()
car_model_options = [model_name for _, model_name in car_model_map]
selected_models = st.multiselect("ì°¨ì¢… ì„ íƒ (1ê°œ ë˜ëŠ” 2ê°œ)", car_model_options)

# ğŸ“„ PDF â†’ VectorStore ë³€í™˜ í•¨ìˆ˜
@st.cache_resource
def load_vectorstore(catalog_path, price_path):
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    docs = []
    for path in [catalog_path, price_path]:
        loader = PyPDFLoader(path)
        docs.extend(text_splitter.split_documents(loader.load()))

    embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
    vectordb = Chroma.from_documents(docs, embedding=embeddings)
    return vectordb

# ğŸ¤– Claudeë¡œ RAG ì‘ë‹µ ìƒì„±
def answer_with_claude(vectorstore, query):
    retriever = vectorstore.as_retriever()
    llm = ChatAnthropicMessages(
        model="claude-3-5-sonnet-20240620",  # ì •í™•í•œ ì´ë¦„
        temperature=0,
        api_key=os.getenv("ANTHROPIC_API_KEY")
    )
    qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)

    with st.spinner("Claude + RAG ì‘ë‹µ ìƒì„± ì¤‘..."):
        return qa_chain.run(query)

# âœ… ë‹¨ì¼ ì°¨ëŸ‰ ì„ íƒ
if len(selected_models) == 1:
    model_rel_path, model_name = next((fp, dn) for fp, dn in car_model_map if dn == selected_models[0])
    base_path = os.path.join(ROOT_DIR, model_rel_path)
    catalog_path = os.path.join(base_path, f"{model_name}-catalog.pdf")
    price_path = os.path.join(base_path, f"{model_name}-price.pdf")

    if not os.path.exists(catalog_path) or not os.path.exists(price_path):
        st.error("ğŸ“‚ í•´ë‹¹ ì°¨ì¢…ì˜ PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        vectordb = load_vectorstore(catalog_path, price_path)
        st.subheader(f"ğŸ“˜ [{model_name.upper()}] ëª¨ë¸ ì§ˆë¬¸í•´ë³´ì„¸ìš”")
        user_input = st.text_input("ê¶ê¸ˆí•œ ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”")

        if user_input:
            rag = answer_with_claude(vectordb, user_input)
            st.markdown("### ğŸ“Œ Claude ê¸°ë°˜ RAG ì‘ë‹µ")
            st.success(rag)

# âœ… ë‘ ê°œ ì„ íƒ ì‹œ ë¹„êµ
elif len(selected_models) == 2:
    st.subheader(f"ğŸ“Š ì°¨ëŸ‰ ë¹„êµ: {selected_models[0]} vs {selected_models[1]}")
    user_input = st.text_input("ë¹„êµí•  ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ê°€ê²©, ì˜µì…˜, ì—°ë¹„ ë“±)")

    def load_both_vectorstores():
        vectordbs = []
        for name in selected_models:
            rel_path, model_name = next((fp, dn) for fp, dn in car_model_map if dn == name)
            base_path = os.path.join(ROOT_DIR, rel_path)
            catalog_path = os.path.join(base_path, f"{model_name}-catalog.pdf")
            price_path = os.path.join(base_path, f"{model_name}-price.pdf")
            if os.path.exists(catalog_path) and os.path.exists(price_path):
                vectordbs.append(load_vectorstore(catalog_path, price_path))
        return vectordbs

    if user_input:
        vectordbs = load_both_vectorstores()
        if len(vectordbs) != 2:
            st.error("ğŸš¨ ë‘ ì°¨ëŸ‰ ëª¨ë‘ PDFê°€ ì¡´ì¬í•´ì•¼ ë¹„êµí•  ìˆ˜ ìˆì–´ìš”.")
        else:
            rag1 = answer_with_claude(vectordbs[0], user_input)
            rag2 = answer_with_claude(vectordbs[1], user_input)

            col1, col2 = st.columns(2)
            with col1:
                st.markdown(f"### ğŸ“˜ {selected_models[0]} (Claude RAG)")
                st.success(rag1)
            with col2:
                st.markdown(f"### ğŸ“˜ {selected_models[1]} (Claude RAG)")
                st.success(rag2)
